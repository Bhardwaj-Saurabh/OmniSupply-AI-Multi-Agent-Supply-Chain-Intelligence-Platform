# OmniSupply: Multi-Agent Supply Chain Intelligence Platform

**Enterprise AI system for automated supply chain insights, risk predictions, and executive reporting.**

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![LangGraph](https://img.shields.io/badge/LangGraph-latest-green.svg)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

---

## ğŸ¯ What is OmniSupply?

OmniSupply is a **production-ready multi-agent AI platform** that ingests real supply chain, sales, and financial data to provide:

- âœ… **Automated Insights**: AI-generated KPI summaries, trend analysis, anomaly detection
- âœ… **Risk Predictions**: Proactive alerts for delivery delays, inventory shortages, quality issues
- âœ… **Process Optimization**: Data-driven recommendations for cost reduction and efficiency
- âœ… **Executive Reporting**: Weekly/monthly CxO-level business intelligence reports
- âœ… **Workflow Automation**: Stakeholder alerts, task creation, meeting agendas

**Current Status**: âœ… **Fully Operational** with 416,962 records loaded across 4 data tables!

---

## ğŸ—ï¸ Architecture

```
User Query â†’ Supervisor Agent â†’ [Data Analyst, Risk, Finance, Meeting, Email Agents]
                â†“
          Aggregation & Report Generation
                â†“
          Executive Summary + Actions
```

**Key Components**:
1. **Data Pipeline**: Ingestion, validation, storage (SQL + Vector DB)
2. **Specialized Agents**: Domain experts (data, risk, finance, reporting, workflow)
3. **Supervisor Agent**: Orchestrates agents, aggregates results, generates reports
4. **Storage Layer**: PostgreSQL + ChromaDB for semantic search

[ğŸ“– Full Architecture Documentation](OMNISUPPLY_ARCHITECTURE.md)

---

## ğŸš€ Quick Start

### 1. Installation

This project uses **[uv](https://github.com/astral-sh/uv)** for fast, reliable Python package management.

```bash
# Clone repository
git clone https://github.com/yourusername/OmniSupply-AI-Multi-Agent-Supply-Chain-Intelligence-Platform.git
cd OmniSupply-AI-Multi-Agent-Supply-Chain-Intelligence-Platform

# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment and install dependencies
uv sync

# This will:
# - Create .venv/ if it doesn't exist
# - Install all dependencies from pyproject.toml
# - Lock versions in uv.lock
```

**Alternative (traditional pip)**:
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2. Setup PostgreSQL Database

**Option A: Local PostgreSQL (Recommended)**

Run the setup script to create a local PostgreSQL instance via Docker:

```bash
bash setup_local_postgres.sh
```

This will:
- Create a PostgreSQL 15 Docker container
- Configure database: `omnisupply`
- Setup user credentials
- Expose on port 5432

**Option B: Remote PostgreSQL**

If you have an existing PostgreSQL server, skip the script and configure your connection in `.env`

### 3. Setup Environment

Create a `.env` file:

```bash
# OpenAI Configuration
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# PostgreSQL Configuration (Local Docker)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=omnisupply
POSTGRES_PASSWORD=omnisupply123
POSTGRES_DB=omnisupply

# Observability
OPIK_PROJECT_NAME=omnisupply
```

### 4. Prepare Data

Place your CSV files in the `data/` directory:

```
data/
â”œâ”€â”€ retail_orders.csv         # DataCo SMART SUPPLY CHAIN dataset
â”œâ”€â”€ supply_chain.csv          # (optional)
â”œâ”€â”€ inventory.csv             # (optional)
â””â”€â”€ financial_data.csv        # (optional)
```

### 5. Load Data into PostgreSQL

```bash
# Load full dataset (180K orders + 351K transactions)
python load_full_data.py

# OR load small dataset for quick testing (10K orders)
python quick_demo_small_data.py
```

### 6. Run Complete Multi-Agent Demo

```bash
# Default: Auto-detect and use existing data (no prompts)
python omnisupply_demo.py

# Force reload: Clear and reload all data from CSV
python omnisupply_demo.py --reload

# Skip data loading: Use existing database only
python omnisupply_demo.py --skip-data
```

This will:
- âœ… Automatically detect and use existing data (no manual prompts)
- âœ… Validate database connection (416,962 records loaded)
- âœ… Initialize all 5 specialized agents
- âœ… Test individual agent capabilities
- âœ… Demonstrate Supervisor multi-agent orchestration
- âœ… Generate executive reports with cross-agent insights

**Example Output**:
```
ğŸ“Š Connecting to PostgreSQL: localhost:5432/omnisupply
âœ… Connected to PostgreSQL successfully!
âœ… Database already contains 65,952 records:
   â€¢ orders: 65,752 records
   â€¢ shipments: 100 records

ğŸ“Š Using existing data (no reload needed)

ğŸ¤– STEP 2: Initializing Agents
âœ… data_analyst: SQL query generation, trend analysis
âœ… risk_agent: Risk assessment, delivery/inventory alerts
âœ… finance_agent: P&L reports, cashflow forecasting
âœ… meeting_agent: Executive summaries, weekly reports
âœ… email_agent: Stakeholder alerts, task automation
```

---

## ğŸ“Š Datasets

The platform currently has **416,962 records loaded** across 4 tables:

### 1. Orders (`retail_orders.csv`)
- Order ID, date, customer segment, region
- Product category, sub-category, pricing
- Discounts, profit, returns, shipping details
- **65,752 records** (deduplicated from 180K raw records)
- Source: DataCo SMART SUPPLY CHAIN dataset

### 2. Financial Transactions (`financial_data.csv`)
- Transaction types (revenue, COGS, expenses, discounts)
- Categories, cost centers, business units
- P&L components, vendor information
- **351,010 records**

### 3. Shipments (`supply_chain.csv`)
- Shipment tracking, carrier, routes
- Expected vs actual delivery dates
- Freight costs, delays, late delivery tracking
- **100 records** (sample data)

### 4. Inventory (`inventory.csv`)
- SKU, product name, warehouse location
- Stock levels, reorder points, reorder quantities
- Lead times, supplier information, unit costs
- **100 records** (sample data)

---

## ğŸ¤– Agent Capabilities

### 1. Data Analyst Agent
- SQL query generation
- Data visualization
- Anomaly detection
- Trend analysis

### 2. Supply Chain Risk Agent
- Multi-dimensional risk scoring
- Late delivery prediction
- Inventory shortage alerts
- Quality issue detection

### 3. Finance Insight Agent
- P&L summarization
- Expense analysis
- Cashflow forecasting (Prophet)
- Budget variance

### 4. Meeting/Report Agent
- Weekly/monthly reports
- CxO executive summaries
- Top 3 recommended actions
- KPI dashboards

### 5. Email/Workflow Agent
- Stakeholder alerts
- Task creation
- Meeting agenda generation
- Follow-up automation

---

## ğŸ’¡ Example Queries

```python
from src.supervisor.orchestrator import SupervisorAgent

supervisor = SupervisorAgent(agent_registry=registry)

# Example 1: Risk analysis
result = supervisor.execute(
    "What are the top 3 supply chain risks this month?"
)

# Example 2: Executive report
result = supervisor.execute(
    "Generate weekly executive summary with KPIs and recommendations"
)

# Example 3: Financial analysis
result = supervisor.execute(
    "Show P&L summary and forecast next 90 days cashflow"
)

# Example 4: Inventory alerts
result = supervisor.execute(
    "Which products are at critical stock levels? Send alerts to operations."
)

print(result['final_report'])
```

---

## ğŸ› ï¸ Project Structure

```
OmniSupply/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ models.py              # Pydantic data models
â”‚   â”‚   â””â”€â”€ ingestion/
â”‚   â”‚       â”œâ”€â”€ loaders.py         # CSV loaders
â”‚   â”‚       â””â”€â”€ validators.py      # Data quality checks
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py          # SQLAlchemy ORM
â”‚   â”‚   â”‚   â””â”€â”€ database.py        # DB client
â”‚   â”‚   â””â”€â”€ vector/
â”‚   â”‚       â”œâ”€â”€ embeddings.py      # Text â†’ vectors
â”‚   â”‚       â””â”€â”€ chromadb_client.py # Vector store
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ base.py                # BaseAgent abstraction
â”‚   â””â”€â”€ supervisor/
â”‚       â””â”€â”€ orchestrator.py        # Supervisor agent
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_analyst_agent_enhanced.ipynb
â”‚   â”œâ”€â”€ supply_chain_risk_agent.ipynb
â”‚   â”œâ”€â”€ finance_insight_agent.ipynb
â”‚   â”œâ”€â”€ meeting_report_agent.ipynb
â”‚   â””â”€â”€ email_workflow_agent.ipynb
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                # Configuration
â”œâ”€â”€ data/                          # Your CSV files here
â”œâ”€â”€ example_usage.py               # Demo script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“ˆ Features

### Data Pipeline
- âœ… Automatic encoding detection
- âœ… Pydantic validation
- âœ… Data quality checks
- âœ… Business rule validation

### Storage
- âœ… SQL (DuckDB/PostgreSQL)
- âœ… Vector DB (ChromaDB + OpenAI embeddings)
- âœ… Bulk operations
- âœ… Semantic search

### Agent Framework
- âœ… BaseAgent abstraction
- âœ… LangGraph workflows
- âœ… Structured LLM outputs (Pydantic)
- âœ… Opik observability

### Supervisor
- âœ… Intelligent query routing
- âœ… Task planning
- âœ… Parallel agent execution
- âœ… Result aggregation
- âœ… Executive report generation

---

## ğŸ”® Roadmap

### Phase 1: Core Platform âœ… **COMPLETED**
- [x] Data ingestion pipeline with validation
- [x] PostgreSQL + ChromaDB storage
- [x] BaseAgent abstraction
- [x] Supervisor orchestration with LangGraph
- [x] Agent notebooks (5 agents)

### Phase 2: Production Agents âœ… **COMPLETED**
- [x] Implement production agent classes (5 agents)
- [x] SQL query generation (Data Analyst)
- [x] Risk scoring models (Risk Agent)
- [x] P&L reporting (Finance Agent)
- [x] Executive report generation (Meeting Agent)
- [x] Alert workflow automation (Email Agent)
- [x] Local PostgreSQL setup via Docker
- [x] Full dataset loaded (416K+ records)

### Phase 3: API Layer
- [ ] FastAPI endpoints
- [ ] Authentication
- [ ] Rate limiting
- [ ] API documentation

### Phase 4: Automation
- [ ] Celery task queue
- [ ] Scheduled reports
- [ ] Real-time monitoring
- [ ] Email integration

### Phase 5: Deployment
- [ ] Docker containers
- [ ] Kubernetes manifests
- [ ] CI/CD pipeline
- [ ] Cloud deployment

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src tests/

# Run specific test
pytest tests/test_data_loader.py
```

---

## ğŸ“š Documentation

- [Architecture Overview](OMNISUPPLY_ARCHITECTURE.md) - Detailed system design
- [Agent Plans](notebooks/) - Individual agent implementations
- [API Documentation](#) - Coming soon

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file

---

## ğŸ™ Acknowledgments

Built with:
- [LangGraph](https://github.com/langchain-ai/langgraph) - Agent workflows
- [OpenAI](https://openai.com) - LLMs (GPT-4o-mini)
- [ChromaDB](https://www.trychroma.com) - Vector search
- [PostgreSQL](https://www.postgresql.org) - Production database
- [Opik](https://www.comet.com/site/products/opik/) - LLM observability
- [Docker](https://www.docker.com) - Local PostgreSQL containerization

---

## ğŸ“§ Contact

Questions or feedback? Open an issue or reach out to the team.

---

**â­ If you find OmniSupply useful, please star the repository!**
